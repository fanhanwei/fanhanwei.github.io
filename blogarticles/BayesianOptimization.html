<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>FAN, Hanwei 樊瀚伟 Blog</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="../index.html" class="logo">FAN, Hanwei</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="../index.html">About me</a></li>
							<li><a href="../RH.html">Recent Highlights</a></li>
							<li class="active"><a href="../Blog.html">Blog</a></li>
						</ul>
						<ul class="icons">
							<li><a href="MAILTO:hanweifan2018@outlook.com" class="icon regular fa-envelope"><span class="label">E-Mail</span></a></li>
							<li><a href="https://www.linkedin.com/in/hanwei-fan-bb3b69192/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://www.instagram.com/fan.hanwei/" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="https://github.com/fanhanwei" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Bayesian Optimization</h1>
								</header>
									<h3>贝叶斯优化</h3>
									<dl>
										<dt>简介</dt>
										<dd>
											<p>贝叶斯优化适用于用尽可能少的数据寻找出函数极值的应用场合。例如石油勘探，每次钻井勘测开销巨大，业主希望用最少的勘测次数找出石油最丰富的地块儿，则贝叶斯优化能够为此提供帮助。</p>
										</dd>
										
										<dt>限制</dt>
										<dd>
											<p> 1. 被测函数有简单的可行域；<br />
												2. 被测函数连续且结构简单，极值易求；<br />
												3. 无需求导，不提供梯度信息；<br />
												4. 训练集数据有限；<br />
												5. 如有噪声，则噪声是独立的且呈正态分布，具有共同但未知的方差。
												</p>
										</dd>
										
										<dt>构建</dt>
										<dd>
											<p> 1. 设计代表模型，对函数建模并定义其先验概率；<br />
												2. 获取训练集，利用贝叶斯规则计算后验概率；<br />
												3. 利用取样函数(acquisition function) &alpha;(x)获得下一个采样点<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>argmax</mi><mn>x</mn></msub><mi>&alpha;(x)</mi></math>。其中取样函数为后验概率的函数；<br />
												4. 新增采样点，并回到步骤二。如此迭代直至收敛或预算耗尽。
												</p>
										</dd>
										
										<dt>相比于active learning</dt>
										<dd>
											<p>主动学习关注全局的分布，会优先将不确定性(variance)最高的点纳入训练集。贝叶斯优化不关注全剧的分布状况，只在意极值点的位置。</p>
										</dd>
										
										<h3>取样函数（acquisition function）</h3>
										<dt>PROBABILITY OF IMPROVEMENT (PI)</dt>
										<dd>
											<p>该方案选择最大值最有可能提高的点作为下一个查询点，注重于减小风险。<br /><img src="../blogimages/b_o1.png" alt="" width="486" height="333"/><br />
											当ϵ增大时，该算法逐渐接近Active Learning，即优先检测不确定性最高的区域。</p>
										</dd>
										
										<dt>EXPECTED IMPROVEMENT (EI)</dt>
										<dd>
											<p>该方案选取最优可能获得最大幅度提高的点作为下一个查询点，注重于提高回报。<br /><img src="../blogimages/b_o2.png" alt="" width="510" height="390"/><br />
											同样，当ϵ增大时，该算法逐渐接近Active Learning，即优先检测不确定性最高的区域。</p>
										</dd>
										
										<dt>Thompson Sampling</dt>
										<dd>
											<p>该方案每一次迭代都从后验中选取一个函数，并对其进行进一步优化。该方案能够在对高不确定性区域进行探索的同时进一步研究已知最大区域。</p>
										</dd>
									</dl>
									
									<h3>在神经网络中使用Bayesian Optimization</h3>
									<p>贝叶斯优化可以帮助我们快速的找到最优超参数，如：学习速率、batch size和激活函数等。一下程序利用scikit-optim实现bayesian optimization。</p>
									<pre><code>log_batch_size = Integer(
  low=2,
  high=7,
  name='log_batch_size'
)
  lr = Real(
  low=1e-6,
  high=1e0,
  prior='log-uniform',
  name='lr'
)
activation = Categorical(
  categories=['relu', 'sigmoid'],
  name='activation'
)

dimensions = [
  dim_num_batch_size_to_base,
  dim_learning_rate,
  dim_activation
]

import gp-minimize from scikit-optim
 # initial parameters (1st point)
default_parameters = 
  [4, 1e-1, 'relu']

# bayesian optimization
  search_result = gp_minimize(
  func=train,
  dimensions=dimensions,
  acq_func='EI', # Expctd Imprv.
  n_calls=11,
  x0=default_parameters
)
									</code></pre>
									
									<h3>GPyOpt Bayesian Optimization Tool</h3>
									<dl>
										<dt>简介</dt>
										<dd>
											<p>GPyOpt黑盒优化器可以简化贝叶斯优化的使用，该工具将帮助我们快速寻找函数的极值。假设f是待测未知函数，我们仅了解其扰动ϵ，故有
											<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>y</mi><mn>i</mn></msub>=f(<msub><mi>x</mi><mn>i</mn></msub>)+<msub><mi>ϵ</mi><mn>i</mn></msub>,&nbsp;with&nbsp;<msub><mi>ϵ</mi><mn>i</mn></msub>~N(0,ψ2)</math>。
											我们需要估测一系列的x，并使得累计后悔值<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mn>N</mn></msub>=Nf(<msub><mi>x</mi><mn>M</mn></msub>)-<msub><mi><msup style="margin-right:-10px"><mi>∑</mi><mi>N</mi></msup></mi><mi>n=1</mi></msub>f(<msub><mi>x</mi><mi>n</mi></msub>)</math>
											最小。所以当我们越快逼近极值时，累计后悔值就越小。</p>
										</dd>
										
										<dt>Gaussian Process（GP)</dt>
										<dd>
											<p>高斯常用于对未知函数建模，可通过均值μ(x)和协方差函数k(x,x′)来参数化。其中协方差函数是GP的核函数，必须是连续、对称且正定的。一种常用的核是平方指数，如下：<br />
												<div align="center"><img src="../blogimages/b_o3.png" alt="" width="234" height="48"/></div><br />其中 σ<sup>2</sup> 和 l 为正。</p>
										</dd>
										
										<dt>构建</dt>
										<dd>
											<p> 1. 设计代表模型，对函数建模并定义其先验概率；<br />
												2. 获取训练集，利用贝叶斯规则计算后验概率；<br />
												3. 利用取样函数(acquisition function) &alpha;(x)获得下一个采样点<math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>argmax</mi><mn>x</mn></msub><mi>&alpha;(x)</mi></math>。其中取样函数为后验概率的函数；<br />
												4. 新增采样点，并回到步骤二。如此迭代直至收敛或预算耗尽。
												</p>
										</dd>
										
										<dt>相比于active learning</dt>
										<dd>
											<p>主动学习关注全局的分布，会优先将不确定性(variance)最高的点纳入训练集。贝叶斯优化不关注全剧的分布状况，只在意极值点的位置。</p>
										</dd>
										
										<h3>取样函数（acquisition function）</h3>
										<dt>PROBABILITY OF IMPROVEMENT (PI)</dt>
										<dd>
											<p>该方案选择最大值最有可能提高的点作为下一个查询点，注重于减小风险。<br /><img src="../blogimages/b_o1.png" alt="" width="486" height="333"/><br />
											当ϵ增大时，该算法逐渐接近Active Learning，即优先检测不确定性最高的区域。</p>
										</dd>
										
										<dt>EXPECTED IMPROVEMENT (EI)</dt>
										<dd>
											<p>该方案选取最优可能获得最大幅度提高的点作为下一个查询点，注重于提高回报。<br /><img src="../blogimages/b_o2.png" alt="" width="510" height="390"/><br />
											同样，当ϵ增大时，该算法逐渐接近Active Learning，即优先检测不确定性最高的区域。</p>
										</dd>
										
										<dt>Thompson Sampling</dt>
										<dd>
											<p>该方案每一次迭代都从后验中选取一个函数，并对其进行进一步优化。该方案能够在对高不确定性区域进行探索的同时进一步研究已知最大区域。</p>
										</dd>
									</dl>
								
								<p>引用自：https://distill.pub/2020/bayesian-optimization/</p>
							</section>
						
						<!-- Footer -->
							<footer>
								<div class="pagination">
									<ul class="actions special">
										<li><a href="../Blog.html" class="button">Back</a></li>
									</ul>
								</div>
							</footer>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>The Hong Kong Univ. of Sci. and Tech.<br />
								Clear Water Bay, Kowloon, Hong Kong, China </p>
							</section>
							<section>
								<h3>Phone</h3>
								<p>Privacy</p>
							</section>
						</section>
						<section class="split contact">
							<section class="alt">
								<h3>Email</h3>
								<p><a href="MAILTO:hanweifan2018@outlook.com">hanweifan2018@outlook.com</a><br />
									You can write to me either in English or Chinese</p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://www.linkedin.com/in/hanwei-fan-bb3b69192/" class="icon brands fa-linkedin"><span class="label">Linkdin</span></a></li>
									<li><a href="https://www.instagram.com/fan.hanwei/" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="https://github.com/fanhanwei" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; FAN, Hanwei. All Rights Reserved.</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>
